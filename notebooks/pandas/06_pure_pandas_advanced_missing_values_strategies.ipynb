{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a336e3-625a-461b-b0d8-bafaa7d8b379",
   "metadata": {},
   "source": [
    "# ðŸ§ª Part 6: Advanced Missing Data Strategies (Transform, Fill, Map)\n",
    "\n",
    "**Goal:** To master advanced, conditional techniques for handling missing data, moving beyond simple global median imputation to methods that preserve the underlying statistical relationships in the data.\n",
    "\n",
    "---\n",
    "### Key Learning Objectives\n",
    "1.  Analyze **missing data patterns** by group (e.g., missing Age by Passenger Class).\n",
    "2.  Implement **Group-Based Imputation** using the powerful `.transform()` method.\n",
    "3.  Use time-series-style imputation: **Forward Fill (`ffill`)** and **Backward Fill (`bfill`)**.\n",
    "4.  Apply custom, **conditional filling logic** using `.map()` and `.apply()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e93dbc-c482-4dec-aae0-6939b9abd828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ADVANCED MISSING VALUE STRATEGIES ===\n",
      "ðŸ“¥ Loaded fresh Titanic data from web\n",
      "âœ… Dataset loaded successfully!\n",
      "Shape: 891 rows Ã— 12 columns\n",
      "\n",
      "ðŸ“‹ First 5 rows:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket   Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.25   NaN        S  \n",
      "1      0          PC 17599  71.28   C85        C  \n",
      "2      0  STON/O2. 3101282   7.92   NaN        S  \n",
      "3      0            113803  53.10  C123        S  \n",
      "4      0            373450   8.05   NaN        S  \n",
      "\n",
      "ðŸ“‹ Column info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set pandas options for better output visualization\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "print(\"=== ADVANCED MISSING VALUE STRATEGIES ===\")\n",
    "\n",
    "# Load the Titanic dataset (using local file as specified)\n",
    "try:\n",
    "    titanic_df = pd.read_csv('titanic_data.csv')\n",
    "    print(\"âœ… Loaded titanic_data.csv\")\n",
    "except FileNotFoundError:\n",
    "    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "    titanic_df = pd.read_csv(url)\n",
    "    print(\"ðŸ“¥ Loaded fresh Titanic data from web\")\n",
    "\n",
    "\n",
    "print(f\"âœ… Dataset loaded successfully!\")\n",
    "print(f\"Shape: {titanic_df.shape[0]} rows Ã— {titanic_df.shape[1]} columns\")\n",
    "\n",
    "\n",
    "# First look at the data\n",
    "print(\"\\nðŸ“‹ First 5 rows:\")\n",
    "print(titanic_df.head())\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“‹ Column info:\")\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd49775-c68a-4ebb-8e93-3f7e0da41f11",
   "metadata": {},
   "source": [
    "## 2. Missing Data Pattern Analysis\n",
    "\n",
    "The first step is to quantify missing data and understand if the missingness is **random** or **conditional**. A conditional pattern (e.g., less `Age` data missing for 1st Class) suggests using sophisticated imputation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b647d84-9a95-4092-a988-4cd33842eb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š 2. Missing Data Pattern Analysis\n",
      "1. Missing Values Count and Percentage:\n",
      "          Missing_Count  Missing_Percentage\n",
      "Cabin               687               77.10\n",
      "Age                 177               19.87\n",
      "Embarked              2                0.22\n",
      "\n",
      "3. Rows with Missing Values Analysis:\n",
      "Rows with missing values: 708 (79.5%)\n",
      "Complete rows: 183 (20.5%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“Š 2. Missing Data Pattern Analysis\")\n",
    "\n",
    "\n",
    "print(\"1. Missing Values Count and Percentage:\")\n",
    "missing_summary = titanic_df.isnull().sum()\n",
    "missing_percentage = (titanic_df.isnull().sum() / len(titanic_df) * 100).round(2)\n",
    "\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'Missing_Count': missing_summary,\n",
    "    'Missing_Percentage': missing_percentage\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "\n",
    "print(missing_analysis[missing_analysis['Missing_Count'] > 0])\n",
    "\n",
    "\n",
    "print(\"\\n3. Rows with Missing Values Analysis:\")\n",
    "# Count rows with any missing values\n",
    "rows_with_missing = titanic_df.isnull().any(axis=1).sum()\n",
    "rows_complete = len(titanic_df) - rows_with_missing\n",
    "\n",
    "\n",
    "print(f\"Rows with missing values: {rows_with_missing} ({rows_with_missing/len(titanic_df)*100:.1f}%)\")\n",
    "print(f\"Complete rows: {rows_complete} ({rows_complete/len(titanic_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa75af-28e6-4b3f-a644-6ae7e25d8e68",
   "metadata": {},
   "source": [
    "## 3. Missing Data Patterns by Passenger Class\n",
    "\n",
    "We use **`groupby()`** to see if the proportion of missing values differs across categories (`Pclass`). If it does, using the global median for imputation is inappropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111521e0-1206-4e19-ae3f-1d217e755572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š 3. Missing Data Patterns by Passenger Class\n",
      "Missing data by Passenger Class:\n",
      "\n",
      "Age missing by class:\n",
      "        Missing_Count  Missing_Percentage\n",
      "Pclass                                   \n",
      "1                  30                13.9\n",
      "2                  11                 6.0\n",
      "3                 136                27.7\n",
      "\n",
      "Cabin missing by class:\n",
      "        Missing_Count  Missing_Percentage\n",
      "Pclass                                   \n",
      "1                  40                18.5\n",
      "2                 168                91.3\n",
      "3                 479                97.6\n",
      "\n",
      "Embarked missing by class:\n",
      "        Missing_Count  Missing_Percentage\n",
      "Pclass                                   \n",
      "1                   2                 0.9\n",
      "2                   0                 0.0\n",
      "3                   0                 0.0\n",
      "\n",
      "ðŸ” Key Insight: Different missing patterns by passenger class reveal potential data collection biases!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“Š 3. Missing Data Patterns by Passenger Class\")\n",
    "print(\"Missing data by Passenger Class:\")\n",
    "\n",
    "# Define columns to check for missingness patterns\n",
    "cols_to_check = ['Age', 'Cabin', 'Embarked']\n",
    "\n",
    "for col in cols_to_check:\n",
    "    # ðŸš¨ Robust Check: Ensure column exists before accessing it\n",
    "    if col not in titanic_df.columns:\n",
    "        print(f\"\\nâš ï¸ Warning: Column '{col}' not found in DataFrame. Skipping pattern analysis.\")\n",
    "        continue\n",
    "\n",
    "    if titanic_df[col].isnull().sum() > 0:\n",
    "        print(f\"\\n{col} missing by class:\")\n",
    "        \n",
    "        missing_by_class = titanic_df.groupby('Pclass')[col].apply(lambda x: x.isnull().sum())\n",
    "        missing_pct_by_class = titanic_df.groupby('Pclass')[col].apply(lambda x: x.isnull().mean() * 100)\n",
    "        \n",
    "        class_analysis = pd.DataFrame({\n",
    "            'Missing_Count': missing_by_class,\n",
    "            'Missing_Percentage': missing_pct_by_class.round(1)\n",
    "        })\n",
    "        print(class_analysis)\n",
    "\n",
    "\n",
    "print(\"\\nðŸ” Key Insight: Different missing patterns by passenger class reveal potential data collection biases!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a1047-b072-4448-9794-ee373b1ac85f",
   "metadata": {},
   "source": [
    "## 4. Group-Based Imputation using `.transform()`\n",
    "\n",
    "The **`.transform()`** method is the key to **conditional imputation**. It calculates a group-specific statistic (like the median) and returns a Series of the *same length* as the original DataFrame, aligned by index. This allows us to fill missing values with the median of their specific subgroup (e.g., the median age of 1st Class women).\n",
    "\n",
    "ðŸŽ¯ **New Syntax:** `df.groupby(['col1', 'col2'])['target'].transform('median')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e310e3b4-5ed1-405c-955d-c3536c53b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š 4. Group-Based Imputation using .transform()\n",
      "\n",
      "Step 1: Analyzing age patterns by class and gender\n",
      "Age statistics by Pclass and Sex:\n",
      "               count  mean  median\n",
      "Pclass Sex                        \n",
      "1      female     85  34.6    35.0\n",
      "       male      101  41.3    40.0\n",
      "2      female     74  28.7    28.0\n",
      "       male       99  30.7    30.0\n",
      "3      female    102  21.8    21.5\n",
      "       male      253  26.5    25.0\n",
      "\n",
      "Step 2: Applying group-based imputation\n",
      "\n",
      "Before imputation (sample missing):\n",
      "    PassengerId  Pclass     Sex  Age\n",
      "5             6       3    male  NaN\n",
      "17           18       2    male  NaN\n",
      "19           20       3  female  NaN\n",
      "\n",
      "âœ… Imputation complete!\n",
      "Missing ages before: 177\n",
      "Missing ages after: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“Š 4. Group-Based Imputation using .transform()\")\n",
    "\n",
    "# Strategy: Fill missing ages with median age by passenger class and gender\n",
    "print(\"\\nStep 1: Analyzing age patterns by class and gender\")\n",
    "age_stats = titanic_df.groupby(['Pclass', 'Sex'])['Age'].agg(['count', 'mean', 'median']).round(1)\n",
    "print(\"Age statistics by Pclass and Sex:\")\n",
    "print(age_stats)\n",
    "\n",
    "\n",
    "print(\"\\nStep 2: Applying group-based imputation\")\n",
    "# Create group-based median ages\n",
    "age_by_group = titanic_df.groupby(['Pclass', 'Sex'])['Age'].transform('median')\n",
    "\n",
    "\n",
    "# Show what transform does\n",
    "print(\"\\nBefore imputation (sample missing):\")\n",
    "sample_missing = titanic_df[titanic_df['Age'].isnull()].head(3)[['PassengerId', 'Pclass', 'Sex', 'Age']]\n",
    "print(sample_missing)\n",
    "\n",
    "\n",
    "# Apply the imputation\n",
    "titanic_df['Age_group_filled'] = titanic_df['Age'].fillna(age_by_group)\n",
    "\n",
    "\n",
    "print(f\"\\nâœ… Imputation complete!\")\n",
    "print(f\"Missing ages before: {titanic_df['Age'].isnull().sum()}\")\n",
    "print(f\"Missing ages after: {titanic_df['Age_group_filled'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b386017-01e4-48b1-901d-1702bafddb25",
   "metadata": {},
   "source": [
    "## 5. Forward Fill and Backward Fill Methods\n",
    "\n",
    "**Forward Fill (`ffill`)** and **Backward Fill (`bfill`)** fill missing values based on adjacent non-null values. They are most appropriate when the row order matters (like in time-series or sequential data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69671572-4b4d-4fcf-b497-20815b10086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š 5. Forward Fill and Backward Fill Methods\n",
      "ðŸŽ¯ New Syntax: df['column'].ffill() and df['column'].bfill()\n",
      "These methods fill missing values based on adjacent non-null values\n",
      "\n",
      "Embarked column missing values: 2\n",
      "\n",
      "ðŸ“‹ Forward/Backward Fill Results:\n",
      "   Original_Missing  After_Forward_Fill  After_Backward_Fill\n",
      "0                 2                   0                    0\n",
      "\n",
      "What values were filled:\n",
      "PassengerId 62: Original=nan, FFill=C, BFill=S\n",
      "PassengerId 830: Original=nan, FFill=Q, BFill=C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nðŸ“Š 5. Forward Fill and Backward Fill Methods\")\n",
    "\n",
    "print(\"ðŸŽ¯ New Syntax: df['column'].ffill() and df['column'].bfill()\")\n",
    "print(\"These methods fill missing values based on adjacent non-null values\")\n",
    "\n",
    "\n",
    "# Work with Embarked column (only 2 missing values)\n",
    "print(f\"\\nEmbarked column missing values: {titanic_df['Embarked'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "# Sort by PassengerId to simulate ordered data\n",
    "titanic_sorted = titanic_df.sort_values('PassengerId').copy()\n",
    "embarked_missing_idx = titanic_sorted[titanic_sorted['Embarked'].isnull()].index\n",
    "\n",
    "\n",
    "# Apply forward fill (FIXED: Using .ffill() method)\n",
    "titanic_sorted['Embarked_ffill'] = titanic_sorted['Embarked'].ffill()\n",
    "\n",
    "\n",
    "# Apply backward fill (FIXED: Using .bfill() method)\n",
    "titanic_sorted['Embarked_bfill'] = titanic_sorted['Embarked'].bfill()\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“‹ Forward/Backward Fill Results:\")\n",
    "fill_comparison = pd.DataFrame({\n",
    "    'Original_Missing': titanic_sorted['Embarked'].isnull().sum(),\n",
    "    'After_Forward_Fill': titanic_sorted['Embarked_ffill'].isnull().sum(),\n",
    "    'After_Backward_Fill': titanic_sorted['Embarked_bfill'].isnull().sum()\n",
    "}, index=[0])\n",
    "print(fill_comparison)\n",
    "\n",
    "\n",
    "# Show what happened to the missing values\n",
    "print(\"\\nWhat values were filled:\")\n",
    "for idx in embarked_missing_idx:\n",
    "    original = titanic_sorted.loc[idx, 'Embarked']\n",
    "    ffill = titanic_sorted.loc[idx, 'Embarked_ffill'] \n",
    "    bfill = titanic_sorted.loc[idx, 'Embarked_bfill']\n",
    "    pid = titanic_sorted.loc[idx, 'PassengerId']\n",
    "    print(f\"PassengerId {pid}: Original={original}, FFill={ffill}, BFill={bfill}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515d0ba-8ff9-4d2f-b285-444635cae404",
   "metadata": {},
   "source": [
    "## 6. Conditional Filling Strategies\n",
    "\n",
    "For categorical features like `Embarked` (port), we fill missing values based on the most common port for a related group (`Pclass`). Using `.map()` with a dictionary of group modes is the most **efficient** and **idiomatic Pandas** way to execute this conditional logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1cfe4a6-70ae-438e-9650-64a4dd14bf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š 6. Conditional Filling Strategies\n",
      "\n",
      "Step 1: Find most common embarkation port by passenger class\n",
      "Most common Embarked port by class:\n",
      "Pclass\n",
      "1    S\n",
      "2    S\n",
      "3    S\n",
      "Name: Embarked, dtype: object\n",
      "\n",
      "Class to Embarked mapping: {1: 'S', 2: 'S', 3: 'S'}\n",
      "\n",
      "âœ… Both filling methods match: True\n",
      "Missing Embarked values after conditional filling: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“Š 6. Conditional Filling Strategies\")\n",
    "\n",
    "\n",
    "# Strategy: Fill missing Embarked based on most common port for each class\n",
    "print(\"\\nStep 1: Find most common embarkation port by passenger class\")\n",
    "embarked_mode_by_class = titanic_df.groupby('Pclass')['Embarked'].apply(\n",
    "    lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'S'\n",
    ")\n",
    "print(\"Most common Embarked port by class:\")\n",
    "print(embarked_mode_by_class)\n",
    "\n",
    "\n",
    "# Method 2 (Efficient): Using pandas map() \n",
    "class_to_embarked = embarked_mode_by_class.to_dict()\n",
    "print(f\"\\nClass to Embarked mapping: {class_to_embarked}\")\n",
    "\n",
    "# Fill missing values using the map() result\n",
    "titanic_df['Embarked_filled_map'] = titanic_df['Embarked'].fillna(\n",
    "    titanic_df['Pclass'].map(class_to_embarked)\n",
    ")\n",
    "\n",
    "\n",
    "# Method 1 (Less Efficient): Using apply() with custom function\n",
    "def fill_embarked_by_class(row):\n",
    "    if pd.isna(row['Embarked']):\n",
    "        return embarked_mode_by_class[row['Pclass']]\n",
    "    return row['Embarked']\n",
    "\n",
    "titanic_df['Embarked_filled_apply'] = titanic_df.apply(fill_embarked_by_class, axis=1)\n",
    "\n",
    "# Verify both methods give same result\n",
    "methods_match = (titanic_df['Embarked_filled_map'] == titanic_df['Embarked_filled_apply']).all()\n",
    "print(f\"\\nâœ… Both filling methods match: {methods_match}\")\n",
    "print(f\"Missing Embarked values after conditional filling: {titanic_df['Embarked_filled_map'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d7f9b5d-31eb-4913-874e-ac676dfafad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ“š SUMMARY: Advanced Missing Value Strategies\n",
      "============================================================\n",
      "\n",
      "âœ… SKILLS MASTERED TODAY:\n",
      "1. Missing data pattern analysis with pandas\n",
      "2. Group-based imputation using .groupby().transform()\n",
      "3. Forward fill and backward fill methods\n",
      "4. Conditional filling with .map() and .fillna()\n",
      "\n",
      "ðŸŽ¯ NEW PANDAS SYNTAX LEARNED:\n",
      "â€¢ df.groupby(['col1', 'col2'])['target'].transform('median')\n",
      "â€¢ df['column'].fillna(method='ffill')  # Forward fill\n",
      "â€¢ df['col'].map(dictionary)  # Value mapping for filling\n",
      "\n",
      "ðŸ”¥ POWER TECHNIQUE OF THE DAY:\n",
      "GROUP-BASED IMPUTATION with .transform()\n",
      "â†’ Fills missing values with group-specific statistics\n",
      "\n",
      "âœ“ Session 6 completed! Sophisticated data cleaning mastered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“š SUMMARY: Advanced Missing Value Strategies\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nâœ… SKILLS MASTERED TODAY:\")\n",
    "print(\"1. Missing data pattern analysis with pandas\")\n",
    "print(\"2. Group-based imputation using .groupby().transform()\")\n",
    "print(\"3. Forward fill and backward fill methods\")\n",
    "print(\"4. Conditional filling with .map() and .fillna()\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ NEW PANDAS SYNTAX LEARNED:\")\n",
    "print(\"â€¢ df.groupby(['col1', 'col2'])['target'].transform('median')\")\n",
    "print(\"â€¢ df['column'].fillna(method='ffill')  # Forward fill\")\n",
    "print(\"â€¢ df['col'].map(dictionary)  # Value mapping for filling\")\n",
    "\n",
    "print(\"\\nðŸ”¥ POWER TECHNIQUE OF THE DAY:\")\n",
    "print(\"GROUP-BASED IMPUTATION with .transform()\")\n",
    "print(\"â†’ Fills missing values with group-specific statistics\")\n",
    "\n",
    "print(\"\\n\" + \"âœ“ Session 6 completed! Sophisticated data cleaning mastered.\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343873d2-cece-4ee3-bad5-93f53ce6b22a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40808298-3b18-4be3-8fb2-f6e32013d8fd",
   "metadata": {},
   "source": [
    "# üíæ Part 7: Pure Pandas Data Type Optimization (Memory Efficiency)\n",
    "\n",
    "**Goal:** To significantly reduce the memory footprint of a DataFrame by optimizing its column data types, using only **100% native Pandas methods** (no NumPy/external libraries needed).\n",
    "\n",
    "---\n",
    "### Key Learning Objectives\n",
    "1.  Analyze memory usage with `.memory_usage(deep=True)`.\n",
    "2.  Master `pd.to_numeric()` for converting messy strings into numbers.\n",
    "3.  Optimize object/string columns using `.astype('category')`.\n",
    "4.  Optimize integer/float columns using smaller types (`uint8`, `float32`).\n",
    "5.  Convert strings to `datetime` objects and extract features using the `.dt` accessor.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814a300c-0140-41cf-87a4-c19bde14f9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PURE PANDAS DATA TYPE OPTIMIZATION ===\n",
      "\n",
      "üîß Environment setup complete! (100% Pandas)\n",
      "‚úÖ Dataset loaded with missing value fixes applied\n",
      "\n",
      "üìã Current Data Types:\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "üíæ Current Memory Usage: 285.64 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "print(\"=== PURE PANDAS DATA TYPE OPTIMIZATION ===\")\n",
    "print(\"\\nüîß Environment setup complete! (100% Pandas)\")\n",
    "\n",
    "# Load the Titanic dataset (continuing from Monday)\n",
    "titanic_url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_df = pd.read_csv(titanic_url)\n",
    "\n",
    "# Apply Monday's missing value fixes using pandas-only methods (Group-based Age Imputation)\n",
    "age_by_group = titanic_df.groupby(['Pclass', 'Sex'])['Age'].transform('median')\n",
    "titanic_df['Age'] = titanic_df['Age'].fillna(age_by_group)\n",
    "\n",
    "# Apply Monday's missing value fixes using pandas-only methods (Mode Imputation)\n",
    "embarked_mode = titanic_df['Embarked'].mode()[0]\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].fillna(embarked_mode)\n",
    "\n",
    "print(\"‚úÖ Dataset loaded with missing value fixes applied\")\n",
    "\n",
    "# Analyze current data types using pure pandas\n",
    "print(\"\\nüìã Current Data Types:\")\n",
    "print(titanic_df.dtypes)\n",
    "\n",
    "print(f\"\\nüíæ Current Memory Usage: {titanic_df.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a806c-ae64-40da-bbc2-58db268c465c",
   "metadata": {},
   "source": [
    "## 2. Handling Messy Numeric Data (`pd.to_numeric()`)\n",
    "\n",
    "Real-world data often stores numbers as strings due to commas, currency symbols, or non-numeric values (like 'unknown').\n",
    "\n",
    "* **Cleanup:** Use Pandas string accessor (`.str`) methods (like `.str.replace()`) to clean the data.\n",
    "* **Conversion:** Use `pd.to_numeric(errors='coerce')` to convert the string column to a proper numeric type, replacing any remaining invalid text with `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ad19bd-edb5-46eb-a673-f87e446cd01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Created messy dataset for practice:\n",
      "  customer_id      age        salary department\n",
      "0         001       25         50000         IT\n",
      "1         002       30        60,000         HR\n",
      "2         003  unknown         70000         IT\n",
      "3         004       35  confidential    Finance\n",
      "4         005       28         55000         HR\n",
      "\n",
      "üìã Original data types:\n",
      "customer_id    object\n",
      "age            object\n",
      "salary         object\n",
      "department     object\n",
      "dtype: object\n",
      "\n",
      "1. Converting Age Column:\n",
      "With errors='coerce': [25.0, 30.0, nan, 35.0, 28.0]\n",
      "\n",
      "2. Converting Salary Column (with preprocessing):\n",
      "Final numeric salaries: [50000.0, 60000.0, 70000.0, nan, 55000.0]\n"
     ]
    }
   ],
   "source": [
    "# Create a messy dataset to demonstrate pandas conversion techniques\n",
    "messy_data = pd.DataFrame({\n",
    "    'customer_id': ['001', '002', '003', '004', '005'],\n",
    "    'age': ['25', '30', 'unknown', '35', '28'],\n",
    "    'salary': ['50000', '60,000', '70000', 'confidential', '55000'],    # Has commas\n",
    "    'department': ['IT', 'HR', 'IT', 'Finance', 'HR'],\n",
    "})\n",
    "\n",
    "print(\"üîß Created messy dataset for practice:\")\n",
    "print(messy_data)\n",
    "print(\"\\nüìã Original data types:\")\n",
    "print(messy_data.dtypes)\n",
    "\n",
    "# Demonstrate different error handling approaches using pandas-only\n",
    "print(\"\\n1. Converting Age Column:\")\n",
    "# Method 1: Coerce errors to NaN (pandas-only)\n",
    "messy_data['age_coerce'] = pd.to_numeric(messy_data['age'], errors='coerce')\n",
    "print(\"With errors='coerce':\", messy_data['age_coerce'].tolist())\n",
    "\n",
    "print(\"\\n2. Converting Salary Column (with preprocessing):\")\n",
    "# Clean salary data first using pandas string methods\n",
    "messy_data['salary_clean'] = messy_data['salary'].str.replace(',', '')\n",
    "# Convert to numeric using pandas\n",
    "messy_data['salary_numeric'] = pd.to_numeric(messy_data['salary_clean'], errors='coerce')\n",
    "print(\"Final numeric salaries:\", messy_data['salary_numeric'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0f3e8-7af7-4e86-9691-afa503d37714",
   "metadata": {},
   "source": [
    "## 3. Advanced Numeric Type Optimization\n",
    "\n",
    "Smaller data types require less memory. We aim to downcast our numeric columns (`int64`, `float64`) to the smallest type that can safely hold the data range without losing information.\n",
    "\n",
    "* **Integer Downcasting:** `int64` ‚Üí `uint8`, `int16`, etc., using `.astype()`.\n",
    "* **Float Downcasting:** `float64` ‚Üí `float32`. This requires checking for **precision loss** before committing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e629dce7-02d6-4c99-8e84-d64caa175a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Optimizing Titanic Dataset Numeric Types\n",
      "\n",
      "1. Applying Integer Optimizations:\n",
      "‚úÖ Integer optimizations applied!\n",
      "\n",
      "2. Applying Float Optimizations:\n",
      "‚úÖ Age: Converted to float32. Memory: 7260 ‚Üí 3696 bytes\n",
      "‚úÖ Fare: Converted to float32. Memory: 7260 ‚Üí 3696 bytes\n"
     ]
    }
   ],
   "source": [
    "# Work with Titanic data for realistic optimization\n",
    "print(\"üéØ Optimizing Titanic Dataset Numeric Types\")\n",
    "titanic_optimized = titanic_df.copy()\n",
    "\n",
    "# Analyze and Apply Integer Optimizations\n",
    "print(\"\\n1. Applying Integer Optimizations:\")\n",
    "# PassengerId can be uint16 (range 1-891)\n",
    "titanic_optimized['PassengerId'] = titanic_optimized['PassengerId'].astype('uint16')\n",
    "# SibSp can be uint8 (range 0-8)\n",
    "titanic_optimized['SibSp'] = titanic_optimized['SibSp'].astype('uint8')\n",
    "# Parch can be uint8 (range 0-6)\n",
    "titanic_optimized['Parch'] = titanic_optimized['Parch'].astype('uint8')\n",
    "print(\"‚úÖ Integer optimizations applied!\")\n",
    "\n",
    "# Analyze and Apply Float Optimizations\n",
    "print(\"\\n2. Applying Float Optimizations:\")\n",
    "float_cols = ['Age', 'Fare']\n",
    "for col in float_cols:\n",
    "    original_memory = titanic_optimized[col].memory_usage(deep=True)\n",
    "    test_float32 = titanic_optimized[col].astype('float32')\n",
    "\n",
    "    # Check for precision loss using pandas comparison\n",
    "    # If the absolute difference between original (float64) and float32 is greater than a threshold (0.01), we lose precision.\n",
    "    diff_series = (titanic_optimized[col] - test_float32).abs()\n",
    "    precision_loss = (diff_series > 0.01).any()\n",
    "\n",
    "    if not precision_loss:\n",
    "        titanic_optimized[col] = test_float32\n",
    "        new_memory = titanic_optimized[col].memory_usage(deep=True)\n",
    "        print(f\"‚úÖ {col}: Converted to float32. Memory: {original_memory} ‚Üí {new_memory} bytes\")\n",
    "    else:\n",
    "        print(f\"‚ùå {col}: Kept as float64 (precision loss detected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177528d3-0cdd-454e-96c6-b3619345113c",
   "metadata": {},
   "source": [
    "## 4. Categorical and Boolean Optimization\n",
    "\n",
    "This is often the source of the biggest memory savings.\n",
    "\n",
    "* **Categorical:** Use `.astype('category')` for string columns with a **low number of unique values** (e.g., `Sex`, `Embarked`). Pandas stores the unique strings once and assigns efficient integer codes to each row.\n",
    "* **Boolean:** Convert `int` columns representing binary data (0/1) to the `bool` type using `.astype('bool')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793f8132-f7b3-4ae8-bf5d-cdbabe104fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Applying Categorical Conversions:\n",
      "‚úÖ Pclass: Optimized memory savings: 7260 ‚Üí 1155 bytes\n",
      "‚úÖ Sex: Optimized memory savings: 47983 ‚Üí 1239 bytes\n",
      "‚úÖ Embarked: Optimized memory savings: 44682 ‚Üí 1281 bytes\n",
      "\n",
      "2. Understanding Categorical Data Structure:\n",
      "Sex categories: ['female', 'male']\n",
      "Sex codes (first 5): [1, 0, 0, 0, 1]\n",
      "\n",
      "3. Boolean Conversion:\n",
      "‚úÖ Survived converted to boolean. Memory: 7260 ‚Üí 1023 bytes\n"
     ]
    }
   ],
   "source": [
    "# Apply categorical conversions using pandas-only\n",
    "print(\"\\n1. Applying Categorical Conversions:\")\n",
    "categorical_cols = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    original_memory = titanic_optimized[col].memory_usage(deep=True)\n",
    "    titanic_optimized[col] = titanic_optimized[col].astype('category')\n",
    "    new_memory = titanic_optimized[col].memory_usage(deep=True)\n",
    "    print(f\"‚úÖ {col}: Optimized memory savings: {original_memory} ‚Üí {new_memory} bytes\")\n",
    "\n",
    "print(\"\\n2. Understanding Categorical Data Structure:\")\n",
    "sex_categorical = titanic_optimized['Sex']\n",
    "print(f\"Sex categories: {sex_categorical.cat.categories.tolist()}\")\n",
    "print(f\"Sex codes (first 5): {sex_categorical.cat.codes[:5].tolist()}\")\n",
    "\n",
    "\n",
    "# Convert Survived column to boolean using pandas-only\n",
    "print(\"\\n3. Boolean Conversion:\")\n",
    "original_memory = titanic_optimized['Survived'].memory_usage(deep=True)\n",
    "titanic_optimized['Survived'] = titanic_optimized['Survived'].astype('bool')\n",
    "new_memory = titanic_optimized['Survived'].memory_usage(deep=True)\n",
    "\n",
    "print(f\"‚úÖ Survived converted to boolean. Memory: {original_memory} ‚Üí {new_memory} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769bd6f8-a6f1-4997-ae53-2265b58250e2",
   "metadata": {},
   "source": [
    "## 5. DateTime Conversion and Feature Extraction\n",
    "\n",
    "Handling dates and times is a specialized form of type optimization.\n",
    "\n",
    "* **Conversion:** Use `pd.to_datetime(errors='coerce')` to convert strings to the `datetime` type.\n",
    "* **Extraction:** Use the `.dt` accessor (e.g., `.dt.year`, `.dt.day_name()`) to extract valuable time-based features from the `datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d01bc0-b8a6-4321-ac8f-fdb15d821c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DateTime Conversion:\n",
      "Original join_date values: ['2023-01-15', '2023-02-20', 'invalid', '2023-03-10', '2023-04-05']\n",
      "Converted to datetime: [Timestamp('2023-01-15 00:00:00'), Timestamp('2023-02-20 00:00:00'), NaT, Timestamp('2023-03-10 00:00:00'), Timestamp('2023-04-05 00:00:00')]\n",
      "\n",
      "2. DateTime Feature Extraction:\n",
      "üìã Extracted datetime features:\n",
      "  join_date_dt  join_year join_weekday_name  join_is_weekend\n",
      "0   2023-01-15     2023.0            Sunday             True\n",
      "1   2023-02-20     2023.0            Monday            False\n",
      "2          NaT        NaN               NaN            False\n",
      "3   2023-03-10     2023.0            Friday            False\n",
      "4   2023-04-05     2023.0         Wednesday            False\n",
      "‚úÖ DateTime feature extraction complete using pandas-only!\n"
     ]
    }
   ],
   "source": [
    "# Create messy date data using pandas-only methods\n",
    "messy_data_dates = pd.DataFrame({\n",
    "    'join_date': ['2023-01-15', '2023-02-20', 'invalid', '2023-03-10', '2023-04-05']\n",
    "})\n",
    "\n",
    "print(\"1. DateTime Conversion:\")\n",
    "print(\"Original join_date values:\", messy_data_dates['join_date'].tolist())\n",
    "\n",
    "# Convert with error handling using pandas\n",
    "messy_data_dates['join_date_dt'] = pd.to_datetime(messy_data_dates['join_date'], errors='coerce')\n",
    "print(\"Converted to datetime:\", messy_data_dates['join_date_dt'].tolist())\n",
    "\n",
    "\n",
    "# Extract features from datetime using pandas .dt accessor\n",
    "print(\"\\n2. DateTime Feature Extraction:\")\n",
    "# Extract various date components using pandas-only\n",
    "messy_data_dates['join_year'] = messy_data_dates['join_date_dt'].dt.year\n",
    "messy_data_dates['join_weekday_name'] = messy_data_dates['join_date_dt'].dt.day_name()\n",
    "messy_data_dates['join_is_weekend'] = messy_data_dates['join_date_dt'].dt.weekday >= 5\n",
    "\n",
    "print(\"üìã Extracted datetime features:\")\n",
    "datetime_features = ['join_date_dt', 'join_year', 'join_weekday_name', 'join_is_weekend']\n",
    "print(messy_data_dates[datetime_features])\n",
    "\n",
    "print(\"‚úÖ DateTime feature extraction complete using pandas-only!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9120528-2148-4409-8f86-d7fe28d9b08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä 6. Final Titanic Optimization Summary\n",
      "========================================\n",
      "Memory usage BEFORE optimization: 285.64 KB\n",
      "Memory usage AFTER optimization: 161.20 KB\n",
      "Total savings: 124.45 KB (43.6%)\n",
      "\n",
      "Optimized data types:\n",
      "PassengerId      uint16\n",
      "Survived           bool\n",
      "Pclass         category\n",
      "Name             object\n",
      "Sex            category\n",
      "Age             float32\n",
      "SibSp             uint8\n",
      "Parch             uint8\n",
      "Ticket           object\n",
      "Fare            float32\n",
      "Cabin            object\n",
      "Embarked       category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Start fresh for final optimization tracking\n",
    "titanic_final = titanic_df.copy()\n",
    "\n",
    "print(\"\\nüìä 6. Final Titanic Optimization Summary\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Memory usage BEFORE optimization: {titanic_final.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "# Apply all optimized types at once for the final DataFrame\n",
    "titanic_final['PassengerId'] = titanic_final['PassengerId'].astype('uint16')\n",
    "titanic_final['SibSp'] = titanic_final['SibSp'].astype('uint8')\n",
    "titanic_final['Parch'] = titanic_final['Parch'].astype('uint8')\n",
    "titanic_final['Survived'] = titanic_final['Survived'].astype('bool')\n",
    "\n",
    "# Apply categorical types\n",
    "categorical_cols = ['Pclass', 'Sex', 'Embarked']\n",
    "for col in categorical_cols:\n",
    "    titanic_final[col] = titanic_final[col].astype('category')\n",
    "\n",
    "# Apply optimized float types (assuming safe conversion from Cell 6)\n",
    "titanic_final['Age'] = titanic_final['Age'].astype('float32')\n",
    "titanic_final['Fare'] = titanic_final['Fare'].astype('float32')\n",
    "\n",
    "final_memory = titanic_final.memory_usage(deep=True).sum() / 1024\n",
    "original_memory = titanic_df.memory_usage(deep=True).sum() / 1024\n",
    "total_savings = original_memory - final_memory\n",
    "savings_percentage = (total_savings / original_memory * 100)\n",
    "\n",
    "print(f\"Memory usage AFTER optimization: {final_memory:.2f} KB\")\n",
    "print(f\"Total savings: {total_savings:.2f} KB ({savings_percentage:.1f}%)\")\n",
    "\n",
    "\n",
    "print(\"\\nOptimized data types:\")\n",
    "print(titanic_final.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f44349-9a33-4b00-90ce-cbccd7c40432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìö SUMMARY: Pure pandas Data Type Optimization\n",
      "============================================================\n",
      "\n",
      "‚úÖ SKILLS MASTERED TODAY (pandas-Only):\n",
      "1. Memory analysis with .memory_usage(deep=True)\n",
      "2. Numeric conversion with pd.to_numeric(errors='coerce')\n",
      "3. Categorical optimization with .astype('category')\n",
      "4. Boolean conversion using .astype('bool')\n",
      "5. DateTime conversion and feature extraction with .dt accessor\n",
      "\n",
      "üî• POWER TECHNIQUE OF THE DAY:\n",
      "PURE PANDAS DATA TYPE OPTIMIZATION\n",
      "‚Üí Achieved 43.6% memory reduction using pandas-only\n",
      "‚Üí Stores categorical data efficiently with integer codes\n",
      "‚Üí Ensures data integrity with precision testing (implicit in our approach)\n",
      "\n",
      "‚úì Session 7 completed! Pure pandas optimization mastered - 43.6% memory saved!\n",
      "üêº 100% pandas-powered, zero external dependencies! üêº\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìö SUMMARY: Pure pandas Data Type Optimization\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚úÖ SKILLS MASTERED TODAY (pandas-Only):\")\n",
    "print(\"1. Memory analysis with .memory_usage(deep=True)\")\n",
    "print(\"2. Numeric conversion with pd.to_numeric(errors='coerce')\")\n",
    "print(\"3. Categorical optimization with .astype('category')\")\n",
    "print(\"4. Boolean conversion using .astype('bool')\")\n",
    "print(\"5. DateTime conversion and feature extraction with .dt accessor\")\n",
    "\n",
    "\n",
    "print(\"\\nüî• POWER TECHNIQUE OF THE DAY:\")\n",
    "print(\"PURE PANDAS DATA TYPE OPTIMIZATION\")\n",
    "print(f\"‚Üí Achieved {savings_percentage:.1f}% memory reduction using pandas-only\")\n",
    "print(\"‚Üí Stores categorical data efficiently with integer codes\")\n",
    "print(\"‚Üí Ensures data integrity with precision testing (implicit in our approach)\")\n",
    "\n",
    "print(f\"\\n‚úì Session 7 completed! Pure pandas optimization mastered - {savings_percentage:.1f}% memory saved!\")\n",
    "print(\"üêº 100% pandas-powered, zero external dependencies! üêº\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa65820-b110-46f4-931e-2b9cf98fd116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

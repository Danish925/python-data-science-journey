{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8446e91f-5b8b-4e62-bfa1-88106564c312",
   "metadata": {},
   "source": [
    "# ðŸ› ï¸ Part 4: Data Preparation - Handling Missing Values and Feature Engineering\n",
    "\n",
    "**Goal:** To understand how to identify, evaluate the impact of, and strategically handle missing data. We will then learn fundamental **Feature Engineering** techniques to create new, predictive columns.\n",
    "\n",
    "---\n",
    "### Key Learning Objectives\n",
    "1.  Quantify missing data using `.isnull().sum()` and percentages.\n",
    "2.  Compare data loss when using different **dropping** strategies (`dropna()`).\n",
    "3.  Implement different **imputation** (filling) strategies, including group-based filling.\n",
    "4.  Create new features like `FamilySize`, `IsAlone`, and `Title` from existing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991972be-bb92-484a-8fb6-5cf8e88e3d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded titanic_snapshot.csv\n",
      "Dataset shape: (891, 12)\n",
      "Columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load previously saved Titanic data or fallback to URL\n",
    "try:\n",
    "    titanic_df = pd.read_csv('data-visualization/data/titanic_snapshot.csv')\n",
    "    print(\"âœ… Loaded titanic_snapshot.csv\")\n",
    "except FileNotFoundError:\n",
    "    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "    titanic_df = pd.read_csv(url)\n",
    "    print(\"ðŸ“¥ Loaded fresh Titanic data from web\")\n",
    "\n",
    "print(f\"Dataset shape: {titanic_df.shape}\")\n",
    "print(f\"Columns: {list(titanic_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d7a283-aede-47b7-a1fa-8268e663b526",
   "metadata": {},
   "source": [
    "## 1. Missing Data Analysis (The Problem)\n",
    "\n",
    "Before any modeling, we must understand data completeness. Missing values can skew statistical results and cause machine learning models to fail.\n",
    "\n",
    "The two main strategies are **Dropping** (removing rows/columns) and **Imputing** (filling in values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2805232-72d9-4b96-8a72-92ef9a0f6f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MISSING DATA ANALYSIS ===\n",
      "Missing values per column:\n",
      "Age         177\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "\n",
      "Missing data percentages:\n",
      "  Age: 19.9%\n",
      "  Cabin: 77.1%\n",
      "  Embarked: 0.2%\n",
      "\n",
      "=== SAMPLE OF MISSING DATA ===\n",
      "Sample passengers with missing age (showing 3 of 177):\n",
      "                            Name     Sex  Age  Pclass  Survived\n",
      "5               Moran, Mr. James    male  NaN       3         0\n",
      "17  Williams, Mr. Charles Eugene    male  NaN       2         1\n",
      "19       Masselmani, Mrs. Fatima  female  NaN       3         1\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n=== MISSING DATA ANALYSIS ===\")\n",
    "\n",
    "# Count missing values per column\n",
    "missing_counts = titanic_df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_counts[missing_counts > 0])\n",
    "\n",
    "# Missing data percentages\n",
    "total_rows = len(titanic_df)\n",
    "missing_percentages = (missing_counts / total_rows) * 100\n",
    "print(f\"\\nMissing data percentages:\")\n",
    "for column, percentage in missing_percentages[missing_percentages > 0].items():\n",
    "    print(f\"  {column}: {percentage:.1f}%\")\n",
    "\n",
    "print(f\"\\n=== SAMPLE OF MISSING DATA ===\")\n",
    "age_missing = titanic_df[titanic_df['Age'].isnull()]\n",
    "print(f\"Sample passengers with missing age (showing 3 of {len(age_missing)}):\")\n",
    "print(age_missing[['Name', 'Sex', 'Age', 'Pclass', 'Survived']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7641a1c9-6743-4b8c-bb79-2652c4e87d80",
   "metadata": {},
   "source": [
    "## 2. Handling Missing Data: Dropping\n",
    "\n",
    "Dropping rows or columns is the simplest solution but risks significant **data loss**. We must assess the trade-off.\n",
    "\n",
    "* **Dropping Rows:** Use `dropna(subset=[...])` to remove rows missing data in specific, important columns.\n",
    "* **Dropping Columns:** If a column (like `Cabin`) is missing too much data (e.g., >70%), it might be better to remove the entire column (`df.drop(['Column'], axis=1)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b90a7f-ef81-49c0-978c-be805b25aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete rows (no missing values): 183\n",
      "Data loss if dropping all missing: 79.5%\n",
      "\n",
      "Cabin column missing: 77.1%\n",
      "Dropped Cabin column - now have 11 columns.\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with ANY missing value\n",
    "complete_rows = titanic_df.dropna()\n",
    "print(f\"Complete rows (no missing values): {len(complete_rows)}\")\n",
    "print(f\"Data loss if dropping all missing: {(len(titanic_df) - len(complete_rows)) / len(titanic_df) * 100:.1f}%\")\n",
    "\n",
    "# Drop the Cabin column if it's mostly empty (over 70% missing)\n",
    "cabin_missing_pct = (titanic_df['Cabin'].isnull().sum() / len(titanic_df)) * 100\n",
    "print(f\"\\nCabin column missing: {cabin_missing_pct:.1f}%\")\n",
    "\n",
    "df_no_cabin = titanic_df.drop(['Cabin'], axis=1)\n",
    "print(f\"Dropped Cabin column - now have {df_no_cabin.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a41673-f61e-4d51-a661-6ee306872285",
   "metadata": {},
   "source": [
    "## 3. Handling Missing Data: Imputation (Filling)\n",
    "\n",
    "Imputation fills missing values, allowing us to keep all rows. The choice of filling value is critical:\n",
    "\n",
    "* **Simple Imputation:** Fill with the **median** (less sensitive to outliers than the mean) or **mode** (for categorical data).\n",
    "* **Smart/Conditional Imputation:** Fill based on the median/mode of *similar* subgroups (e.g., filling a woman's age with the median age of all other women)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385238ae-c43b-44ef-a200-2ddff82e244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled Age missing values with overall median: 28.0\n",
      "\n",
      "Age patterns by Sex and Class:\n",
      "Sex     Pclass\n",
      "female  1         35.0\n",
      "        2         28.0\n",
      "        3         21.5\n",
      "male    1         40.0\n",
      "        2         30.0\n",
      "        3         25.0\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Filled Embarked missing values with most common: 'S'\n"
     ]
    }
   ],
   "source": [
    "df_filled = titanic_df.copy()\n",
    "\n",
    "# Simple Imputation for Age\n",
    "median_age = df_filled['Age'].median()\n",
    "df_filled['Age_filled_median'] = df_filled['Age'].fillna(median_age)\n",
    "print(f\"Filled Age missing values with overall median: {median_age:.1f}\")\n",
    "\n",
    "# Smart Imputation for Age (Group-based)\n",
    "age_by_group = df_filled.groupby(['Sex', 'Pclass'])['Age'].median()\n",
    "print(\"\\nAge patterns by Sex and Class:\")\n",
    "print(age_by_group.round(1))\n",
    "\n",
    "df_filled['Age_filled_smart'] = df_filled['Age']\n",
    "for (sex, pclass), median_age in age_by_group.items():\n",
    "    mask = (df_filled['Sex'] == sex) & (df_filled['Pclass'] == pclass) & (df_filled['Age'].isnull())\n",
    "    df_filled.loc[mask, 'Age_filled_smart'] = median_age\n",
    "\n",
    "# Imputation for Categorical (Embarked)\n",
    "most_common_port = df_filled['Embarked'].mode()[0]\n",
    "df_filled['Embarked_filled'] = df_filled['Embarked'].fillna(most_common_port)\n",
    "print(f\"\\nFilled Embarked missing values with most common: '{most_common_port}'\")\n",
    "\n",
    "# Imputation for Cabin (Treating missing as a category)\n",
    "df_filled['Cabin_filled'] = df_filled['Cabin'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe422c-894b-43ea-a472-8ec776f5b1ab",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering (Creating New Data)\n",
    "\n",
    "Feature engineering is the process of creating new columns (features) from existing ones to give the model better predictive power.\n",
    "\n",
    "Common techniques include:\n",
    "* **Combining:** `SibSp` + `Parch` to get `FamilySize`.\n",
    "* **Extracting:** Getting the `Title` from the `Name` string.\n",
    "* **Transforming:** Categorizing numerical data (e.g., `Age` to `AgeGroup`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3c034a-9027-4bcb-9758-cd8ab40b9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age group distribution:\n",
      "AgeGroup\n",
      "Adult    812\n",
      "Child     68\n",
      "Elder     11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Passengers traveling alone: 537\n",
      "Simplified title distribution:\n",
      "Title_simple\n",
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Other      27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Deck distribution:\n",
      "Deck\n",
      "Unknown    687\n",
      "C           59\n",
      "B           47\n",
      "D           33\n",
      "E           32\n",
      "A           15\n",
      "F           13\n",
      "G            4\n",
      "T            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_features = df_filled.copy()\n",
    "\n",
    "# Feature 1: Age Group (Transformation)\n",
    "def categorize_age(age):\n",
    "    if pd.isnull(age):\n",
    "        return 'Unknown'\n",
    "    elif age < 12:\n",
    "        return 'Child'\n",
    "    elif age < 65:\n",
    "        return 'Adult'\n",
    "    else:\n",
    "        return 'Elder'\n",
    "\n",
    "df_features['AgeGroup'] = df_features['Age_filled_smart'].apply(categorize_age)\n",
    "print(\"Age group distribution:\")\n",
    "print(df_features['AgeGroup'].value_counts())\n",
    "\n",
    "# Feature 2 & 3: Family Size and Is Alone (Combining and Binary)\n",
    "df_features['FamilySize'] = df_features['SibSp'] + df_features['Parch'] + 1\n",
    "df_features['IsAlone'] = (df_features['FamilySize'] == 1).astype(int)\n",
    "print(f\"\\nPassengers traveling alone: {df_features['IsAlone'].sum()}\")\n",
    "\n",
    "# Feature 4: Title (Extraction)\n",
    "df_features['Title'] = df_features['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master'\n",
    "}\n",
    "df_features['Title_simple'] = df_features['Title'].map(title_mapping).fillna('Other')\n",
    "print(\"Simplified title distribution:\")\n",
    "print(df_features['Title_simple'].value_counts())\n",
    "\n",
    "# Feature 5: Deck (Extraction and Categorical)\n",
    "df_features['Deck'] = df_features['Cabin'].str[0].fillna('Unknown')\n",
    "print(f\"\\nDeck distribution:\")\n",
    "print(df_features['Deck'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7156d0a0-184d-4207-91a9-e718d9a28661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLEANING IMPACT ON SIZE ===\n",
      "  Original: 891 rows, 12 columns\n",
      "  Filled_Smart: 891 rows, 16 columns\n",
      "  With_Features: 891 rows, 22 columns\n",
      "\n",
      "=== IMPACT ON KEY INSIGHTS (Gender Survival) ===\n",
      "Original Data:\n",
      "  Female survival: 74.2%\n",
      "  Male survival: 18.9%\n",
      "\n",
      "Filled_Smart Data:\n",
      "  Female survival: 74.2%\n",
      "  Male survival: 18.9%\n",
      "\n",
      "With_Features Data:\n",
      "  Female survival: 74.2%\n",
      "  Male survival: 18.9%\n",
      "\n",
      "\n",
      "ðŸ“ Exported datasets:\n",
      "- titanic_minimal_clean.csv: 891 rows, basic cleaning\n",
      "- titanic_smart_filled.csv: 891 rows, advanced filling\n",
      "- titanic_with_features.csv: 891 rows, 15 columns\n",
      "\n",
      "ðŸŽ¯ KEY LEARNING:\n",
      "Strategic cleaning and feature engineering are essential steps that directly impact model performance and analytical conclusions!\n"
     ]
    }
   ],
   "source": [
    "# Summary Printout\n",
    "datasets = {\n",
    "    'Original': titanic_df,\n",
    "    'Filled_Smart': df_filled,\n",
    "    'With_Features': df_features\n",
    "}\n",
    "\n",
    "print(f\"\\n=== CLEANING IMPACT ON SIZE ===\")\n",
    "for name, df in datasets.items():\n",
    "    print(f\"  {name}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "\n",
    "print(f\"\\n=== IMPACT ON KEY INSIGHTS (Gender Survival) ===\")\n",
    "for name, df in datasets.items():\n",
    "    if 'Survived' in df.columns and 'Sex' in df.columns:\n",
    "        gender_survival = df.groupby('Sex')['Survived'].mean()\n",
    "        print(f\"{name} Data:\")\n",
    "        for gender, rate in gender_survival.items():\n",
    "            print(f\"  {gender.capitalize()} survival: {rate:.1%}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "# Export cleaned datasets\n",
    "os.makedirs('data-visualization/data', exist_ok=True)\n",
    "\n",
    "# 1. Minimal Clean (for comparison)\n",
    "minimal_clean = titanic_df.dropna(subset=['Survived', 'Sex', 'Pclass'])\n",
    "minimal_clean.to_csv('data-visualization/data/titanic_minimal_clean.csv', index=False)\n",
    "\n",
    "# 2. Smart Filled Data\n",
    "smart_clean_cols = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex',\n",
    "                   'Age_filled_smart', 'SibSp', 'Parch', 'Fare', 'Embarked_filled']\n",
    "smart_clean = df_filled[smart_clean_cols].copy()\n",
    "smart_clean.columns = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex',\n",
    "                       'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "smart_clean.to_csv('data-visualization/data/titanic_smart_filled.csv', index=False)\n",
    "\n",
    "# 3. Featured Data (The most ready-to-model set)\n",
    "feature_columns = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age_filled_smart',\n",
    "                   'SibSp', 'Parch', 'Fare', 'Embarked_filled',\n",
    "                   'AgeGroup', 'FamilySize', 'IsAlone', 'Title_simple', 'Deck']\n",
    "featured_data = df_features[feature_columns].copy()\n",
    "featured_data = featured_data.rename(columns={'Age_filled_smart': 'Age', 'Embarked_filled': 'Embarked'})\n",
    "featured_data.to_csv('data-visualization/data/titanic_with_features.csv', index=False)\n",
    "\n",
    "print(f\"\\nðŸ“ Exported datasets:\")\n",
    "print(f\"- titanic_minimal_clean.csv: {len(minimal_clean)} rows, basic cleaning\")\n",
    "print(f\"- titanic_smart_filled.csv: {len(smart_clean)} rows, advanced filling\")\n",
    "print(f\"- titanic_with_features.csv: {len(featured_data)} rows, {len(featured_data.columns)} columns\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ KEY LEARNING:\")\n",
    "print(\"Strategic cleaning and feature engineering are essential steps that directly impact model performance and analytical conclusions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc5998-213b-40e9-bc5c-4e33da6d0ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

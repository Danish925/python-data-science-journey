{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a910b61f-28d1-40e8-8121-21e401543b44",
   "metadata": {},
   "source": [
    "# ‚úçÔ∏è Part 8: Pure Pandas String Processing and Feature Engineering\n",
    "\n",
    "**Goal:** To transform raw, messy text columns (`Name`, `Ticket`, `Cabin`) into high-signal numerical and categorical features using **100% native Pandas string methods (`.str`) and regular expressions**.\n",
    "\n",
    "---\n",
    "### Key Learning Objectives\n",
    "1.  Master string manipulation: `.str.split()`, `.str.len()`, `.str.contains()`.\n",
    "2.  Use the **`.str.extract()`** method with regex to pull specific features (e.g., `Title`, `Ticket Prefix`).\n",
    "3.  Create complex social features (`Family_Name`, `Title_Grouped`, `Shared_Ticket_Count`).\n",
    "4.  Implement safeguards for arithmetic operations involving categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eba7f59-8b11-48f7-b7d2-db35f3485b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PURE PANDAS STRING PROCESSING & FEATURE ENGINEERING ===\n",
      "üîß Applying prior enhancements using pandas-only...\n",
      "‚úÖ Dataset enhanced with prior improvements using pandas-only!\n",
      "Dataset shape: (891, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re  # Built-in Python regular expressions\n",
    "\n",
    "# Set pandas display options for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"=== PURE PANDAS STRING PROCESSING & FEATURE ENGINEERING ===\")\n",
    "\n",
    "# Load the Titanic dataset (continuing from previous notebooks)\n",
    "titanic_url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_df = pd.read_csv(titanic_url)\n",
    "\n",
    "# Apply all prior enhancements (Imputation and Type Optimization) using pandas-only methods\n",
    "print(\"üîß Applying prior enhancements using pandas-only...\")\n",
    "\n",
    "# 1. Missing value fixes (Group-based Age Imputation, Mode Embarked Imputation)\n",
    "age_by_group = titanic_df.groupby(['Pclass', 'Sex'])['Age'].transform('median')\n",
    "titanic_df['Age'] = titanic_df['Age'].fillna(age_by_group)\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0])\n",
    "\n",
    "# 2. Data type optimizations (Categorical, Boolean, Float)\n",
    "titanic_df['Pclass'] = titanic_df['Pclass'].astype('category')\n",
    "titanic_df['Sex'] = titanic_df['Sex'].astype('category')\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].astype('category')\n",
    "titanic_df['Survived'] = titanic_df['Survived'].astype('bool')\n",
    "\n",
    "print(\"‚úÖ Dataset enhanced with prior improvements using pandas-only!\")\n",
    "print(f\"Dataset shape: {titanic_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60773109-e1b1-408a-a053-a1fc8f5e7e40",
   "metadata": {},
   "source": [
    "## 2. String Accessor (`.str`) Basics and Pattern Detection\n",
    "\n",
    "The `.str` accessor allows us to apply string methods element-wise to every string in a Series.\n",
    "\n",
    "* **Information:** `.str.len()`, `.str.split()`.\n",
    "* **Detection:** `.str.contains()`, `.str.startswith()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c490e0-c5b8-4978-9d92-ff634c641e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä 2. Basic String Information and Pattern Detection\n",
      "\n",
      "1. Basic String Information:\n",
      "Name length statistics:\n",
      "count    891.000000\n",
      "mean      26.965208\n",
      "std        9.281607\n",
      "min       12.000000\n",
      "25%       20.000000\n",
      "50%       25.000000\n",
      "75%       30.000000\n",
      "max       82.000000\n",
      "Name: Name_Length, dtype: float64\n",
      "Shortest name: Lam, Mr. Ali\n",
      "Longest name: Penasco y Castellana, Mrs. Victor de Satode (Maria Josefa Perez de Soto y Vallejo)\n",
      "\n",
      "Names with parentheses: 143\n",
      "Names with quotes: 53\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä 2. Basic String Information and Pattern Detection\")\n",
    "\n",
    "# 1. Basic Information and Length Analysis\n",
    "print(\"\\n1. Basic String Information:\")\n",
    "titanic_df['Name_Length'] = titanic_df['Name'].str.len()\n",
    "print(\"Name length statistics:\")\n",
    "print(titanic_df['Name_Length'].describe())\n",
    "\n",
    "# Find shortest and longest names using pandas methods\n",
    "shortest_idx = titanic_df['Name_Length'].idxmin()\n",
    "longest_idx = titanic_df['Name_Length'].idxmax()\n",
    "print(f\"Shortest name: {titanic_df.loc[shortest_idx, 'Name']}\")\n",
    "print(f\"Longest name: {titanic_df.loc[longest_idx, 'Name']}\")\n",
    "\n",
    "\n",
    "# 2. Pattern Detection: Parentheses and Quotes\n",
    "# Check for parentheses (maiden names, nicknames) using pandas regex\n",
    "titanic_df['Has_Parentheses'] = titanic_df['Name'].str.contains(r'\\(.*\\)', na=False, regex=True)\n",
    "parentheses_count = titanic_df['Has_Parentheses'].sum()\n",
    "print(f\"\\nNames with parentheses: {parentheses_count}\")\n",
    "\n",
    "# Check for quotes (nicknames) using pandas string methods\n",
    "titanic_df['Has_Quotes'] = titanic_df['Name'].str.contains('\"', na=False, regex=False)\n",
    "quotes_count = titanic_df['Has_Quotes'].sum()\n",
    "print(f\"Names with quotes: {quotes_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933196a-ff48-4d93-becb-421763d86639",
   "metadata": {},
   "source": [
    "## 3. String Splitting (`.str.split()`) and Regex Extraction (`.str.extract()`)\n",
    "\n",
    "This is where we turn a single text column into multiple structural features.\n",
    "\n",
    "* **Splitting:** `.str.split(', ', expand=True)` splits the name into Last Name and the rest.\n",
    "* **Extraction (Power Technique):** `.str.extract(r'pattern')` uses regular expressions to precisely capture specific text, like the title, by using **capture groups** (parentheses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d781f2-1db1-4a78-9af3-e1e6886fe9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä 3. Splitting and Regex Extraction for Name\n",
      "‚úÖ Family names extracted using pandas\n",
      "Unique family names: 667\n",
      "\n",
      "‚úÖ Raw Titles extracted using pandas regex!\n",
      "üìã Raw Title distribution (top 15):\n",
      "Title_Raw\n",
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Dr          7\n",
      "Rev         6\n",
      "Col         2\n",
      "Mlle        2\n",
      "Major       2\n",
      "Ms          1\n",
      "Mme         1\n",
      "Don         1\n",
      "Lady        1\n",
      "Sir         1\n",
      "Capt        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìã Grouped title distribution (Simplified):\n",
      "Title_Grouped\n",
      "Mr         517\n",
      "Miss       185\n",
      "Mrs        126\n",
      "Master      40\n",
      "Dr           7\n",
      "Rev          6\n",
      "Officer      5\n",
      "Royalty      4\n",
      "Other        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä 3. Splitting and Regex Extraction for Name\")\n",
    "\n",
    "# 1. Splitting Names into Components\n",
    "# Most Titanic names follow pattern: \"Lastname, Title Firstname\"\n",
    "name_parts = titanic_df['Name'].str.split(', ', expand=True, n=1)\n",
    "name_parts.columns = ['Last_Name', 'First_Title']\n",
    "\n",
    "# Extract family name and title components\n",
    "titanic_df['Family_Name'] = name_parts['Last_Name']\n",
    "titanic_df['First_Title_Part'] = name_parts['First_Title']\n",
    "\n",
    "print(\"‚úÖ Family names extracted using pandas\")\n",
    "print(f\"Unique family names: {titanic_df['Family_Name'].nunique()}\")\n",
    "\n",
    "\n",
    "# 2. Title Extraction with Regex\n",
    "# Pattern: comma, optional space, capture word(s), period\n",
    "title_pattern = r', ([^.]*)\\.'\n",
    "titanic_df['Title_Raw'] = titanic_df['Name'].str.extract(title_pattern)\n",
    "\n",
    "print(\"\\n‚úÖ Raw Titles extracted using pandas regex!\")\n",
    "print(\"üìã Raw Title distribution (top 15):\")\n",
    "print(titanic_df['Title_Raw'].value_counts().head(15))\n",
    "\n",
    "\n",
    "# 3. Advanced Title Cleaning and Grouping\n",
    "title_mapping = {\n",
    "    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "    'Dr': 'Dr', 'Rev': 'Rev', 'Col': 'Officer', 'Major': 'Officer',\n",
    "    'Capt': 'Officer', 'Countess': 'Royalty', 'Lady': 'Royalty', \n",
    "    'Sir': 'Royalty', 'Don': 'Royalty', 'Dona': 'Royalty', \n",
    "    'Jonkheer': 'Royalty', 'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'\n",
    "}\n",
    "\n",
    "titanic_df['Title_Grouped'] = titanic_df['Title_Raw'].str.strip().map(title_mapping)\n",
    "titanic_df['Title_Grouped'] = titanic_df['Title_Grouped'].fillna('Other')\n",
    "\n",
    "print(\"\\nüìã Grouped title distribution (Simplified):\")\n",
    "print(titanic_df['Title_Grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28b18f-97fb-4a4d-9c1c-a7964d09e4d8",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering from Cabin, Ticket, and Family Data\n",
    "\n",
    "We apply the same string processing logic to derive high-signal features from other columns.\n",
    "\n",
    "* **Cabin:** Extract `Deck` letter.\n",
    "* **Ticket:** Extract `Prefix` and create a `Shared_Ticket` flag.\n",
    "* **Family:** Combine `SibSp` and `Parch` to capture social context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f25394da-a5f0-4dcb-973f-37b787da08da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Cabin Analysis and Feature Engineering\n",
      "‚úÖ Cabin decks extracted. Distribution:\n",
      "Cabin_Deck\n",
      "Unknown    687\n",
      "C           59\n",
      "B           47\n",
      "D           33\n",
      "E           32\n",
      "A           15\n",
      "F           13\n",
      "G            4\n",
      "T            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Ticket Pattern Analysis\n",
      "‚úÖ Ticket prefixes extracted. Top 5:\n",
      "Ticket_Prefix\n",
      "NONE     661\n",
      "PC        60\n",
      "CA        41\n",
      "A         28\n",
      "STONO     18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Family Feature Engineering\n",
      "‚úÖ Family size and social features created and merged.\n"
     ]
    }
   ],
   "source": [
    "# 1. Cabin Analysis and Feature Engineering\n",
    "print(\"\\nüìä Cabin Analysis and Feature Engineering\")\n",
    "\n",
    "# Extract Deck (first character) from cabin using pandas string methods\n",
    "titanic_df['Cabin_Deck'] = titanic_df['Cabin'].str[0]\n",
    "titanic_df['Cabin_Deck'] = titanic_df['Cabin_Deck'].fillna('Unknown')\n",
    "titanic_df['Has_Cabin'] = titanic_df['Cabin'].notna().astype(int)\n",
    "\n",
    "print(f\"‚úÖ Cabin decks extracted. Distribution:\\n{titanic_df['Cabin_Deck'].value_counts()}\")\n",
    "\n",
    "\n",
    "# 2. Ticket Pattern Analysis\n",
    "print(\"\\nüìä Ticket Pattern Analysis\")\n",
    "\n",
    "# Extract non-numeric prefix from tickets using pandas string methods\n",
    "def extract_ticket_prefix_pandas(ticket_series):\n",
    "    # Remove all digits and clean up using pandas string methods\n",
    "    prefix_series = ticket_series.str.replace(r'\\d+', '', regex=True).str.strip()\n",
    "    prefix_series = prefix_series.str.replace(r'[./\\s]', '', regex=True).str.strip()\n",
    "    # Replace empty strings with 'NONE' using pandas where\n",
    "    prefix_series = prefix_series.where(prefix_series != '', 'NONE')\n",
    "    return prefix_series\n",
    "\n",
    "titanic_df['Ticket_Prefix'] = extract_ticket_prefix_pandas(titanic_df['Ticket'])\n",
    "print(f\"‚úÖ Ticket prefixes extracted. Top 5:\\n{titanic_df['Ticket_Prefix'].value_counts().head(5)}\")\n",
    "\n",
    "# Ticket sharing (same ticket number across multiple passengers)\n",
    "ticket_sharing = titanic_df.groupby('Ticket').size()\n",
    "titanic_df['Shared_Ticket_Count'] = titanic_df['Ticket'].map(ticket_sharing)\n",
    "titanic_df['Has_Shared_Ticket'] = (titanic_df['Shared_Ticket_Count'] > 1).astype('int8')\n",
    "\n",
    "\n",
    "# 3. Family Feature Engineering\n",
    "print(\"\\nüìä Family Feature Engineering\")\n",
    "# Build on existing SibSp and Parch using pandas arithmetic\n",
    "titanic_df['Family_Size'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1\n",
    "titanic_df['Is_Alone'] = (titanic_df['Family_Size'] == 1).astype(int)\n",
    "\n",
    "# Analyze families traveling together using pandas groupby\n",
    "family_name_stats = titanic_df.groupby('Family_Name').agg({\n",
    "    'PassengerId': 'count',\n",
    "    'Survived': 'mean',\n",
    "    'Fare': 'mean',\n",
    "}).round(3)\n",
    "\n",
    "# Flatten column names and merge back\n",
    "family_name_stats.columns = ['Family_Count', 'Family_Survival_Rate', 'Family_Avg_Fare']\n",
    "titanic_df = titanic_df.merge(family_name_stats, left_on='Family_Name', right_index=True, how='left')\n",
    "\n",
    "print(\"‚úÖ Family size and social features created and merged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ef5d3-7bea-4609-8b85-03eb4a68c78f",
   "metadata": {},
   "source": [
    "## 5. Safe Interaction Features (Respecting Categoricals)\n",
    "\n",
    "When creating interaction features between numeric and categorical data, **never perform arithmetic directly on a categorical column**. Always cast the categorical column to a numeric Series temporarily for the calculation.\n",
    "\n",
    "* **`Age_Class_Ratio`:** Age divided by a numeric representation of `Pclass`.\n",
    "* **`Fare_Per_Person`:** Fare divided by `Family_Size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb8f82b3-48fc-42d9-aeec-b142e1fea90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Safe Interaction Features\n",
      "\n",
      "üìà Feature correlations with survival (abs-sorted):\n",
      "Name_Length            0.332\n",
      "Has_Cabin              0.317\n",
      "Fare_Per_Person        0.222\n",
      "Age_Class_Ratio        0.160\n",
      "Shared_Ticket_Count    0.038\n",
      "Family_Size            0.017\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä Safe Interaction Features\")\n",
    "\n",
    "# 1. Create a temporary numeric Series for Pclass strictly for math\n",
    "# Cast Pclass (which is 'category') to an integer Series\n",
    "pclass_num = titanic_df['Pclass'].astype('int16')\n",
    "\n",
    "# 2. Create core interactions\n",
    "titanic_df['Fare_Per_Person'] = (titanic_df['Fare'] / titanic_df['Family_Size']).astype('float32')\n",
    "\n",
    "# Avoid division by zero, though Pclass should be 1-3\n",
    "safe_pclass_divisor = pclass_num.replace(0, pd.NA)\n",
    "titanic_df['Age_Class_Ratio'] = (titanic_df['Age'] / safe_pclass_divisor).astype('float32')\n",
    "\n",
    "# 3. Final Quality Check (Correlations)\n",
    "numeric_features = [\n",
    "    'Family_Size', 'Has_Cabin', 'Shared_Ticket_Count', \n",
    "    'Fare_Per_Person', 'Age_Class_Ratio', 'Name_Length'\n",
    "]\n",
    "# Correlate features with survival, casting Survived bool to int for correlation\n",
    "corr = titanic_df[numeric_features].corrwith(titanic_df['Survived'].astype('int8')).sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nüìà Feature correlations with survival (abs-sorted):\")\n",
    "print(corr.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95babc62-c4fd-4588-a1bd-b31ac44d35d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Session 8 Summary: Pure pandas String Processing & Feature Engineering ===\n",
      "Goal: Create interpretable, pandas-only features from Names, Tickets, and Cabins,\n",
      "      plus safe interactions that respect categorical dtypes.\n",
      "\n",
      "‚úÖ SKILLS MASTERED TODAY (pandas-Only):\n",
      "1. String Extraction: .str.extract(r'pattern') to get Title, Ticket components.\n",
      "2. String Splitting: .str.split() for initial component separation.\n",
      "3. Categorical Logic: .str.contains() and .str.len() for binary and numeric flags.\n",
      "4. Social Features: Combining SibSp and Parch for Family_Size; merging Family_Survival_Rate.\n",
      "5. Arithmetic Safeguard: Temporarily casting categorical Pclass to int for Age_Class_Ratio.\n",
      "\n",
      "üî• POWER TECHNIQUE OF THE DAY:\n",
      "REGEX EXTRACTION (`.str.extract`)\n",
      "‚Üí Enables precise feature capture (e.g., Title, Deck letter) from unstructured text.\n",
      "\n",
      "üí° KEY INSIGHTS:\n",
      "‚Ä¢ High-Signal Features: Title_Grouped, Fare_Per_Person, and Has_Cabin are typically strong predictors.\n",
      "‚Ä¢ Memory Efficiency: String processing often increases memory initially, but prior categorical/integer optimization is key.\n",
      "\n",
      "üìù REUSABLE FEATURES CREATED:\n",
      "‚Ä¢ Title_Grouped (Categorical, Social Status)\n",
      "‚Ä¢ Cabin_Deck (Categorical, Wealth Indicator)\n",
      "‚Ä¢ Fare_Per_Person (Numeric, Normalized Fare)\n",
      "‚Ä¢ Family_Size, Is_Alone (Numeric, Social Context)\n",
      "\n",
      "‚úì Session 8 completed! Complex feature engineering mastered - ready for EDA and Visualization! üêº\n"
     ]
    }
   ],
   "source": [
    "def session8_summary():\n",
    "    # Final check on savings percentage using only the most essential features\n",
    "    original_memory_cols = ['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch']\n",
    "    final_memory_cols = ['Title_Grouped', 'Ticket_Prefix', 'Cabin_Deck', 'Family_Size', 'Has_Cabin']\n",
    "\n",
    "    original_memory = titanic_df[original_memory_cols].memory_usage(deep=True).sum() / 1024\n",
    "    final_memory = titanic_df[final_memory_cols].memory_usage(deep=True).sum() / 1024\n",
    "    \n",
    "    # Check for division by zero before calculating savings percentage\n",
    "    savings_percentage = ((original_memory - final_memory) / original_memory * 100).round(1) if original_memory > 0 else 0\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"=== Session 8 Summary: Pure pandas String Processing & Feature Engineering ===\")\n",
    "    lines.append(\"Goal: Create interpretable, pandas-only features from Names, Tickets, and Cabins,\")\n",
    "    lines.append(\"      plus safe interactions that respect categorical dtypes.\\n\")\n",
    "    \n",
    "    lines.append(\"‚úÖ SKILLS MASTERED TODAY (pandas-Only):\")\n",
    "    lines.append(\"1. String Extraction: .str.extract(r'pattern') to get Title, Ticket components.\")\n",
    "    lines.append(\"2. String Splitting: .str.split() for initial component separation.\")\n",
    "    lines.append(\"3. Categorical Logic: .str.contains() and .str.len() for binary and numeric flags.\")\n",
    "    lines.append(\"4. Social Features: Combining SibSp and Parch for Family_Size; merging Family_Survival_Rate.\")\n",
    "    lines.append(\"5. Arithmetic Safeguard: Temporarily casting categorical Pclass to int for Age_Class_Ratio.\")\n",
    "\n",
    "    lines.append(\"\\nüî• POWER TECHNIQUE OF THE DAY:\")\n",
    "    lines.append(\"REGEX EXTRACTION (`.str.extract`)\")\n",
    "    lines.append(\"‚Üí Enables precise feature capture (e.g., Title, Deck letter) from unstructured text.\")\n",
    "\n",
    "    lines.append(\"\\nüí° KEY INSIGHTS:\")\n",
    "    lines.append(\"‚Ä¢ High-Signal Features: Title_Grouped, Fare_Per_Person, and Has_Cabin are typically strong predictors.\")\n",
    "    lines.append(f\"‚Ä¢ Memory Efficiency: String processing often increases memory initially, but prior categorical/integer optimization is key.\")\n",
    "\n",
    "    lines.append(\"\\nüìù REUSABLE FEATURES CREATED:\")\n",
    "    lines.append(\"‚Ä¢ Title_Grouped (Categorical, Social Status)\")\n",
    "    lines.append(\"‚Ä¢ Cabin_Deck (Categorical, Wealth Indicator)\")\n",
    "    lines.append(\"‚Ä¢ Fare_Per_Person (Numeric, Normalized Fare)\")\n",
    "    lines.append(\"‚Ä¢ Family_Size, Is_Alone (Numeric, Social Context)\")\n",
    "\n",
    "    lines.append(f\"\\n‚úì Session 8 completed! Complex feature engineering mastered - ready for EDA and Visualization! üêº\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(session8_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88178c-23e1-4784-95d4-f1ec85e9e760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
